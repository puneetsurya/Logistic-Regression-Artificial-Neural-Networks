{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Deep Learning"},{"metadata":{},"cell_type":"markdown","source":"Deep learning is a machine learning technique that teaches computers to do what comes naturally to humans: learn by example. Deep learning is a key technology behind driverless cars, enabling them to recognize a stop sign, or to distinguish a pedestrian from a lamppost. It is the key to voice control in consumer devices like phones, tablets, TVs, and hands-free speakers. Deep learning is getting lots of attention lately and for good reason. It’s achieving results that were not possible before.\n\nIn deep learning, a computer model learns to perform classification tasks directly from images, text, or sound. Deep learning models can achieve state-of-the-art accuracy, sometimes exceeding human-level performance. Models are trained by using a large set of labeled data and neural network architectures that contain many layers."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Importing the libraries\nimport numpy as np \nimport pandas as pd \n# reading the dataset\ndataset = pd.read_csv('../input/Churn_Modelling.csv')\ndataset.head()","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"   RowNumber  CustomerId   ...   EstimatedSalary  Exited\n0          1    15634602   ...         101348.88       1\n1          2    15647311   ...         112542.58       0\n2          3    15619304   ...         113931.57       1\n3          4    15701354   ...          93826.63       0\n4          5    15737888   ...          79084.10       0\n\n[5 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RowNumber</th>\n      <th>CustomerId</th>\n      <th>Surname</th>\n      <th>CreditScore</th>\n      <th>Geography</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>15634602</td>\n      <td>Hargrave</td>\n      <td>619</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>2</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>15647311</td>\n      <td>Hill</td>\n      <td>608</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>41</td>\n      <td>1</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>15619304</td>\n      <td>Onio</td>\n      <td>502</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>8</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>15701354</td>\n      <td>Boni</td>\n      <td>699</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>39</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>15737888</td>\n      <td>Mitchell</td>\n      <td>850</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>2</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.info()","execution_count":2,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 10000 entries, 0 to 9999\nData columns (total 14 columns):\nRowNumber          10000 non-null int64\nCustomerId         10000 non-null int64\nSurname            10000 non-null object\nCreditScore        10000 non-null int64\nGeography          10000 non-null object\nGender             10000 non-null object\nAge                10000 non-null int64\nTenure             10000 non-null int64\nBalance            10000 non-null float64\nNumOfProducts      10000 non-null int64\nHasCrCard          10000 non-null int64\nIsActiveMember     10000 non-null int64\nEstimatedSalary    10000 non-null float64\nExited             10000 non-null int64\ndtypes: float64(2), int64(9), object(3)\nmemory usage: 1.1+ MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.describe()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"         RowNumber    CustomerId      ...       EstimatedSalary        Exited\ncount  10000.00000  1.000000e+04      ...          10000.000000  10000.000000\nmean    5000.50000  1.569094e+07      ...         100090.239881      0.203700\nstd     2886.89568  7.193619e+04      ...          57510.492818      0.402769\nmin        1.00000  1.556570e+07      ...             11.580000      0.000000\n25%     2500.75000  1.562853e+07      ...          51002.110000      0.000000\n50%     5000.50000  1.569074e+07      ...         100193.915000      0.000000\n75%     7500.25000  1.575323e+07      ...         149388.247500      0.000000\nmax    10000.00000  1.581569e+07      ...         199992.480000      1.000000\n\n[8 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RowNumber</th>\n      <th>CustomerId</th>\n      <th>CreditScore</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10000.00000</td>\n      <td>1.000000e+04</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.00000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n      <td>10000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5000.50000</td>\n      <td>1.569094e+07</td>\n      <td>650.528800</td>\n      <td>38.921800</td>\n      <td>5.012800</td>\n      <td>76485.889288</td>\n      <td>1.530200</td>\n      <td>0.70550</td>\n      <td>0.515100</td>\n      <td>100090.239881</td>\n      <td>0.203700</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2886.89568</td>\n      <td>7.193619e+04</td>\n      <td>96.653299</td>\n      <td>10.487806</td>\n      <td>2.892174</td>\n      <td>62397.405202</td>\n      <td>0.581654</td>\n      <td>0.45584</td>\n      <td>0.499797</td>\n      <td>57510.492818</td>\n      <td>0.402769</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00000</td>\n      <td>1.556570e+07</td>\n      <td>350.000000</td>\n      <td>18.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>11.580000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2500.75000</td>\n      <td>1.562853e+07</td>\n      <td>584.000000</td>\n      <td>32.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>51002.110000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5000.50000</td>\n      <td>1.569074e+07</td>\n      <td>652.000000</td>\n      <td>37.000000</td>\n      <td>5.000000</td>\n      <td>97198.540000</td>\n      <td>1.000000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>100193.915000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7500.25000</td>\n      <td>1.575323e+07</td>\n      <td>718.000000</td>\n      <td>44.000000</td>\n      <td>7.000000</td>\n      <td>127644.240000</td>\n      <td>2.000000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>149388.247500</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>10000.00000</td>\n      <td>1.581569e+07</td>\n      <td>850.000000</td>\n      <td>92.000000</td>\n      <td>10.000000</td>\n      <td>250898.090000</td>\n      <td>4.000000</td>\n      <td>1.00000</td>\n      <td>1.000000</td>\n      <td>199992.480000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"There are no null values in the data, hence the data is clean. Remove the columns that are not required for the dataset and changing the dataframe to numpy array by dividing the dependent and independent variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset.drop(['RowNumber','CustomerId','Surname'], axis=1)\ndataset.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"   CreditScore Geography   ...   EstimatedSalary  Exited\n0          619    France   ...         101348.88       1\n1          608     Spain   ...         112542.58       0\n2          502    France   ...         113931.57       1\n3          699    France   ...          93826.63       0\n4          850     Spain   ...          79084.10       0\n\n[5 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CreditScore</th>\n      <th>Geography</th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>619</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>2</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>608</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>41</td>\n      <td>1</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>502</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>42</td>\n      <td>8</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>699</td>\n      <td>France</td>\n      <td>Female</td>\n      <td>39</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>850</td>\n      <td>Spain</td>\n      <td>Female</td>\n      <td>43</td>\n      <td>2</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Feature selection, converting the categorical to numerical."},{"metadata":{"trusted":true},"cell_type":"code","source":"geography = pd.get_dummies(dataset['Geography'],drop_first=True)\n# similarly for Gender colimn as well. If there are n dummy columns, consider n-1 so drop any one of the columns.\ngender = pd.get_dummies(dataset['Gender'],drop_first=True)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = dataset.drop(['Geography','Gender'], axis=1)\n# add the columns to the original dataset.\ndataset = pd.concat([dataset,geography,gender],axis=1)\ndataset.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"   CreditScore  Age  Tenure    Balance  ...   Exited  Germany  Spain  Male\n0          619   42       2       0.00  ...        1        0      0     0\n1          608   41       1   83807.86  ...        0        0      1     0\n2          502   42       8  159660.80  ...        1        0      0     0\n3          699   39       1       0.00  ...        0        0      0     0\n4          850   43       2  125510.82  ...        0        0      1     0\n\n[5 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CreditScore</th>\n      <th>Age</th>\n      <th>Tenure</th>\n      <th>Balance</th>\n      <th>NumOfProducts</th>\n      <th>HasCrCard</th>\n      <th>IsActiveMember</th>\n      <th>EstimatedSalary</th>\n      <th>Exited</th>\n      <th>Germany</th>\n      <th>Spain</th>\n      <th>Male</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>619</td>\n      <td>42</td>\n      <td>2</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>101348.88</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>608</td>\n      <td>41</td>\n      <td>1</td>\n      <td>83807.86</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>112542.58</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>502</td>\n      <td>42</td>\n      <td>8</td>\n      <td>159660.80</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113931.57</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>699</td>\n      <td>39</td>\n      <td>1</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>93826.63</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>850</td>\n      <td>43</td>\n      <td>2</td>\n      <td>125510.82</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79084.10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Spearating dependent and independent variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dataset.drop(\"Exited\",axis=1)\ny = dataset['Exited']","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature scaling can vary your results a lot while using certain algorithms and have a minimal or no effect in others. Example : if the data has the balance column in rupees and paise, then it will be scaled either to rupees or paise."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2, random_state = 0)\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before fitting the model, let us understand the terms:\n\n**fit**: when you want to train your model without any pre-processing on\nthe data\n\n**transform**: when you want to do pre-processing on the data\nusing one of the functions from sklearn.preprocessing\n\n**fit_transform**(): It's same as calling fit() and then transform() - a\nshortcut\n\n**Please go through this link for a better understanding**\n\nhttps://ml-cheatsheet.readthedocs.io/en/latest/nn_concepts.html#weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","execution_count":9,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/opt/conda/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n  return self.fit(X, **fit_params).transform(X)\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n  \n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing the Keras libraries and packages\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n# Initialising the ANN\nclassifier = Sequential()","execution_count":10,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"The Keras Python library for deep learning focuses on the creation of models as a sequence of layers. The simplest model is defined in the Sequential class which is a linear stack of Layers.\nYou can create a Sequential model and define all of the layers in the constructor, as below."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding the input layer and the first hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n# Adding the second hidden layer\nclassifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n# Adding the output layer\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform',activation = 'sigmoid'))","execution_count":11,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**Input Layer**\n\nHolds the data your model will train on. Each neuron in the input layer represents a unique attribute in your dataset (e.g. height, hair color, etc.).\n\n**Hidden Layer**\n\nSits between the input and output layers and applies an activation function before passing on the results. There are often multiple hidden layers in a network. In traditional networks, hidden layers are typically fully-connected layers — each neuron receives input from all the previous layer’s neurons and sends its output to every neuron in the next layer. This contrasts with how convolutional layers work where the neurons send their output to only some of the neurons in the next layer.\n\n**Output Layer**\n\nThe final layer in a network. It receives input from the previous hidden layer, optionally applies an activation function, and returns an output representing your model’s prediction.\n\n**Definition of activation function**:- Activation function decides, whether a neuron should be activated or not by calculating weighted sum and further adding bias with it. The purpose of the activation function is to introduce non-linearity into the output of a neuron.\n\n**Explanation** :-\nWe know, neural network has neurons that work in correspondence of weight, bias and their respective activation function. In a neural network, we would update the weights and biases of the neurons on the basis of the error at the output. This process is known as back-propagation. Activation functions make the back-propagation possible since the gradients are supplied along with the error to update the weights and biases."},{"metadata":{},"cell_type":"markdown","source":"ReLU (Rectified Linear Unit) Activation Function. The ReLU is the most used activation function in the world right now.Since, it is used in almost all the convolutional neural networks or deep learning."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**adam** : Adam is an optimization algorithm that can used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.summary()","execution_count":13,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 6)                 72        \n_________________________________________________________________\ndense_2 (Dense)              (None, 6)                 42        \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 7         \n=================================================================\nTotal params: 121\nTrainable params: 121\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting the ANN to the Training set\nhistory = classifier.fit(X_train, y_train, batch_size = 10, epochs = 10)","execution_count":14,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nEpoch 1/10\n8000/8000 [==============================] - 1s 187us/step - loss: 0.4792 - acc: 0.7960\nEpoch 2/10\n8000/8000 [==============================] - 1s 110us/step - loss: 0.4283 - acc: 0.7960\nEpoch 3/10\n8000/8000 [==============================] - 1s 110us/step - loss: 0.4216 - acc: 0.7995\nEpoch 4/10\n8000/8000 [==============================] - 1s 114us/step - loss: 0.4175 - acc: 0.8244\nEpoch 5/10\n8000/8000 [==============================] - 1s 111us/step - loss: 0.4160 - acc: 0.8272\nEpoch 6/10\n8000/8000 [==============================] - 1s 111us/step - loss: 0.4141 - acc: 0.8296\nEpoch 7/10\n8000/8000 [==============================] - 1s 109us/step - loss: 0.4127 - acc: 0.8312\nEpoch 8/10\n8000/8000 [==============================] - 1s 108us/step - loss: 0.4109 - acc: 0.8326\nEpoch 9/10\n8000/8000 [==============================] - 1s 110us/step - loss: 0.4099 - acc: 0.8331\nEpoch 10/10\n8000/8000 [==============================] - 1s 111us/step - loss: 0.4088 - acc: 0.8327\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"One epoch means that each sample in the training dataset has had an opportunity to update the internal model parameters. An epoch is comprised of one or more batches. For example, as above, an epoch that has one batch is called the batch gradient descent learning algorithm.\n\nYou can think of a for-loop over the number of epochs where each loop proceeds over the training dataset. Within this for-loop is another nested for-loop that iterates over each batch of samples, where one batch has the specified “batch size” number of samples"},{"metadata":{"trusted":true},"cell_type":"code","source":"#history\n# Part 3 - Making predictions and evaluating the model\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)\ny_pred[:5]","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"array([[False],\n       [False],\n       [False],\n       [False],\n       [False]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making the classification report\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nprint(classification_report(y_test,y_pred))\n","execution_count":16,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       0.85      0.98      0.91      1595\n           1       0.77      0.30      0.43       405\n\n   micro avg       0.84      0.84      0.84      2000\n   macro avg       0.81      0.64      0.67      2000\nweighted avg       0.83      0.84      0.81      2000\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(accuracy_score(y_test, y_pred)*100)","execution_count":17,"outputs":[{"output_type":"stream","text":"84.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)","execution_count":18,"outputs":[{"output_type":"stream","text":"[[1560   35]\n [ 285  120]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = classifier.evaluate(X_test,y_test)\nprint(score)\nprint('loss = ', score[0])\nprint('acc = ', score[1])","execution_count":19,"outputs":[{"output_type":"stream","text":"2000/2000 [==============================] - 0s 41us/step\n[0.40701151728630064, 0.84]\nloss =  0.40701151728630064\nacc =  0.84\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change the epochs to 5, 10 from 2\n# we got 79% acc with 2 & 5 & 20 epochs with SGD\n# we got 83% acc with 20 epochs with adam\n# Initialising the ANN\nclassifier = Sequential()\nclassifier.add(Dense(units = 20, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n# Adding the second hidden layer\nclassifier.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'relu'))\n# Adding the third hidden layer\nclassifier.add(Dense(units = 20, kernel_initializer = 'uniform', activation = 'relu'))\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nhistory = classifier.fit(X_train, y_train, batch_size = 10, epochs = 20)","execution_count":20,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n8000/8000 [==============================] - 1s 172us/step - loss: 0.4562 - acc: 0.7960\nEpoch 2/20\n8000/8000 [==============================] - 1s 130us/step - loss: 0.4215 - acc: 0.8131\nEpoch 3/20\n8000/8000 [==============================] - 1s 132us/step - loss: 0.4149 - acc: 0.8322\nEpoch 4/20\n8000/8000 [==============================] - 1s 129us/step - loss: 0.4088 - acc: 0.8354\nEpoch 5/20\n8000/8000 [==============================] - 1s 132us/step - loss: 0.4054 - acc: 0.8355\nEpoch 6/20\n8000/8000 [==============================] - 1s 130us/step - loss: 0.4045 - acc: 0.8347\nEpoch 7/20\n8000/8000 [==============================] - 1s 133us/step - loss: 0.4023 - acc: 0.8355\nEpoch 8/20\n8000/8000 [==============================] - 1s 134us/step - loss: 0.4012 - acc: 0.8360\nEpoch 9/20\n8000/8000 [==============================] - 1s 134us/step - loss: 0.4005 - acc: 0.8340\nEpoch 10/20\n8000/8000 [==============================] - 1s 132us/step - loss: 0.4001 - acc: 0.8386\nEpoch 11/20\n8000/8000 [==============================] - 1s 132us/step - loss: 0.3998 - acc: 0.8371\nEpoch 12/20\n8000/8000 [==============================] - 1s 134us/step - loss: 0.3990 - acc: 0.8371\nEpoch 13/20\n8000/8000 [==============================] - 1s 131us/step - loss: 0.3984 - acc: 0.8355\nEpoch 14/20\n8000/8000 [==============================] - 1s 130us/step - loss: 0.3981 - acc: 0.8369\nEpoch 15/20\n8000/8000 [==============================] - 1s 130us/step - loss: 0.3979 - acc: 0.8365\nEpoch 16/20\n8000/8000 [==============================] - 1s 134us/step - loss: 0.3973 - acc: 0.8386\nEpoch 17/20\n8000/8000 [==============================] - 1s 132us/step - loss: 0.3978 - acc: 0.8362\nEpoch 18/20\n8000/8000 [==============================] - 1s 133us/step - loss: 0.3964 - acc: 0.8402\nEpoch 19/20\n8000/8000 [==============================] - 1s 138us/step - loss: 0.3965 - acc: 0.8360\nEpoch 20/20\n8000/8000 [==============================] - 1s 141us/step - loss: 0.3956 - acc: 0.8392\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)\ny_pred[:5]","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"array([[False],\n       [False],\n       [False],\n       [False],\n       [False]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nprint(classification_report(y_test,y_pred))","execution_count":22,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       0.86      0.95      0.90      1595\n           1       0.68      0.40      0.51       405\n\n   micro avg       0.84      0.84      0.84      2000\n   macro avg       0.77      0.68      0.71      2000\nweighted avg       0.83      0.84      0.82      2000\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Making the Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, y_pred)\nprint(cm)","execution_count":23,"outputs":[{"output_type":"stream","text":"[[1517   78]\n [ 241  164]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = classifier.evaluate(X_test,y_test)\nprint(score)\nprint('loss = ', score[0])\nprint('acc = ', score[1])","execution_count":24,"outputs":[{"output_type":"stream","text":"2000/2000 [==============================] - 0s 51us/step\n[0.39525816226005556, 0.8405]\nloss =  0.39525816226005556\nacc =  0.8405\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(accuracy_score(y_test, y_pred)*100)","execution_count":25,"outputs":[{"output_type":"stream","text":"84.05\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"More the epoch's, more the accuracy score! :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}